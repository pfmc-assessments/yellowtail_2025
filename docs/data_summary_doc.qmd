---
title: "Data summary"
date: today
format: 
  html:
    toc: true
    output-file: "index"
editor: visual
---

```{r opts, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(here)
library(dplyr)
library(ggplot2)
theme_set(theme_classic())
```

This documents data streams for use in the Northern Yellowtail Rockfish stock assessment. These data are NOT final and have NOT been fully QA/QC'ed! They are here for communication with the STAT and other collaborators. It is not official communication of the National Oceanic and Atmospheric Administration or the United States Department of Commerce.

## Landings

### Commercial landings

Some summary figures:

```{r pacfin-catch, cache=TRUE}
load(here('data/confidential/commercial/pacfin_12-11-2024/PacFIN.YTRK.CompFT.11.Dec.2024.RData'))
# I have checked and LANDING_YEAR = PACFIN_YEAR for all rows.

yt_n_catch_pacfin <- catch.pacfin |>
  filter(
    AGENCY_CODE == 'W' | AGENCY_CODE == 'O' | COUNTY_NAME == 'DEL NORTE' | COUNTY_NAME == 'HUMBOLDT', # OR, WA, N. CA
    LANDING_YEAR < 2024
  )

# OR landings time series
or_comm_catch <- read.csv(here("Data/Confidential/commercial/Oregon Commercial landings_433_2023.csv")) |>
  tibble::as_tibble() |>
  group_by(YEAR) |>
  summarise(catch_mt = sum(TOTAL)) |>
  mutate(AGENCY_CODE = 'O')

# WA URCK/UPOP reconstruction, use prior to 2000
wa_urck <- read.csv(here('Data/Raw_not_confidential/WA_URCK_UPOP_recon_1981-2016.csv')) |>
  filter(Species_AfterComps %in% c('YTRK', 'YTR1'), 
         Year < 2001) |> 
  group_by(Year) |>
  summarise(catch_mt = sum(RoundPounds_AfterComps) * 0.453592 / 1000) |>
  mutate(AGENCY_CODE = 'W') |>
  rename(YEAR = Year)

# Put it all together
comm_draft_landings <- yt_n_catch_pacfin |> 
  filter(AGENCY_CODE != 'O',
         AGENCY_CODE != 'W' | PACFIN_YEAR >= 2001
         ) |> 
  group_by(PACFIN_YEAR, AGENCY_CODE)|>
  summarise(catch_mt = sum(ROUND_WEIGHT_MTONS)) |>
  rename(YEAR = PACFIN_YEAR) |>
  bind_rows(
    or_comm_catch,
    wa_urck
  )|> 
  group_by(YEAR, AGENCY_CODE) |>
  summarise(catch_mt = sum(catch_mt)) |>
  filter(YEAR >= 1981) 

# 2017 assessment landings
comm2017 <- read.csv(here("Data/Raw_not_confidential/commercial_catch_2017.csv")) |> 
  as_tibble() |>
  tidyr::replace_na(list(Mirick.reconstructed.POP1.URCK = 0)) |>
  mutate(O = OR.Recent..MT. + Mirick.reconstructed.POP1.URCK + OR.Hist..MT.,
         W = as.numeric(stringr::str_remove(WA, ','))) |> 
  select(Year, W, C = CA.North..MT., O) |>
  filter(Year >= 1981) |>
  tidyr::pivot_longer(-Year, names_to = 'AGENCY_CODE', values_to = 'catch_mt') |>
  mutate(model = '2017')

# landings by state
comm_draft_landings |>
  ggplot() +
  geom_col(aes(x = YEAR, y = catch_mt, fill = AGENCY_CODE)) +
  ggtitle('Commercial landings through 2023 by state') +
  viridis::scale_fill_viridis(discrete = TRUE)

# landings by gear type
yt_n_catch_pacfin |>
  group_by(PACFIN_GROUP_GEAR_CODE, LANDING_YEAR) |>
  summarise(catch_mt = sum(ROUND_WEIGHT_MTONS)) |>
  ggplot() +
  geom_col(aes(x = LANDING_YEAR, y = catch_mt, fill = factor(PACFIN_GROUP_GEAR_CODE, levels = c('TWL', 'MSC', 'NET', 'POT', 'TLS', 'TWS', 'HKL')))) +
  ggtitle('Commercial landings through 2023 by gear') +
  labs(fill = 'PacFIN gear group', x = 'YEAR') +
  viridis::scale_fill_viridis(discrete = TRUE)

# total catch by gear over time with midwater trawl separated
yt_n_catch_pacfin |>
  mutate(geargroup2 = ifelse(PACFIN_GEAR_CODE == "MDT", yes = "MDT", no = PACFIN_GROUP_GEAR_CODE)) |> # split midwater trawl as MDT
  group_by(geargroup2, LANDING_YEAR) |>
  summarise(catch_mt = sum(ROUND_WEIGHT_MTONS)) |>
  ggplot() +
  geom_col(aes(x = LANDING_YEAR, y = catch_mt, fill = factor(geargroup2, levels = c("TWL", "MDT", "MSC", "NET", "POT", "TLS", "TWS", "HKL")))) +
  ggtitle("Commercial landings through 2023 by gear with midwater trawl separated") +
  labs(fill = "PacFIN gear group\n(MDT = midwater trawl)", x = 'YEAR') #+
  # viridis::scale_fill_viridis(discrete = TRUE) # colors were hard to see in viridis

# compare 2017 landings to current landings, by state
comm_draft_landings |>
  rename(Year = YEAR) |>
  mutate(model = 'current') |>
  bind_rows(comm2017) |> 
  ggplot() +
  geom_line(aes(x = Year, y = catch_mt, col = AGENCY_CODE, linetype = model), linewidth = 1) +
  viridis::scale_color_viridis(discrete = TRUE) +
  labs(title = 'Comparing commercial landings in 2017 model vs current', x = 'YEAR')
```

Table of commercial landings by state, 1981 onward.

```{r comm-catch-tbl}
comm_draft_landings |>
  mutate(State = case_when(AGENCY_CODE == 'C' ~ 'CA',
                           AGENCY_CODE == 'O' ~ 'OR',
                           AGENCY_CODE == 'W' ~ 'WA')) |>
  select(-AGENCY_CODE) |>
  tidyr::pivot_wider(names_from = State, values_from = catch_mt) |>
  knitr::kable(align = 'l', digits = 1)
```

WDFW has alerted the STAT these do not include all tribal catches in recent years. 1981-2000 are from the UPOP/URCK reconstruction, summing catches for YTRK and YTR1. 2001 onward comes from PacFIN

Oregon landings were provided directly to the STAT from ODFW and come from PacFIN and a UPOP/URCK reconstruction. 

California landings are for catch landed into Del Norte and Humboldt counties only.

### At-Sea landings

```{r ashop-catch}
ashop_catch <- readxl::read_excel(
  here("Data/Confidential/ASHOP/Oken_YLT_Catch data_1976-2023_102824_ASHOP.xlsx"), 
  sheet = 'Catch Summary Table')
ashop_catch |>
  mutate(catch_mt = EXPANDED_SumOfEXTRAPOLATED_2SECTOR_WEIGHT_KG / 1000) |>
  select(YEAR, catch_mt) |>
  knitr::kable(align = 'l', digits = 1)
```

### Recreational landings

```{r rec-catch-modern}
# WASHINGTON
wa_modern <- read.csv(here('Data/Confidential/Rec/CTE501-WASHINGTON-1990---2023.csv')) |> 
  filter(RECFIN_WATER_AREA_NAME != 'Canada', RECFIN_YEAR <= 2023, 
         RECFIN_CATCH_AREA_NAME != 'SEKIU AND PILLAR POINT') |>
  tibble::as_tibble() |> 
  group_by(RECFIN_YEAR) |> 
  summarise(Dead_Catch = sum(TOTAL_MORTALITY_MT)) |>
  mutate(State = 'WA (mt)')

wa_historical <- read.csv(here('Data/Raw_not_confidential/WA_historical_rec.csv')) |>
  tibble::as_tibble() |>
  filter(AREA %in% 1:4) |> # these are marine areas, per T. Tsou on 12/10/24 in meeting notes
  group_by(RECFIN_YEAR) |>
  summarise(Dead_Catch = sum(RETAINED_NUM)) |>
  mutate(State = 'WA (numbers)')

# OREGON
or_rec_catch <- read.csv(here("Data/Confidential/Rec/Oregon Recreational landings_433_2023.csv")) |>
  tibble::as_tibble() |>
  mutate(State = 'OR (mt)') |>
  select(RECFIN_YEAR = Year, Dead_Catch = Total_MT, State)

# CALIFORNIA
ca_modern <- read.csv(here('Data/Raw_not_confidential/RecFIN_CA_catch_to_2023.csv')) |>
  filter(grepl("Redwood", DISTRICT_NAME)) |>
  tibble::as_tibble() |>
  group_by(RECFIN_YEAR) |>
  summarise(Dead_Catch = sum(SUM_TOTAL_MORTALITY_MT)) |>
  mutate(State = 'CA (mt)',
         to_add = ifelse(RECFIN_YEAR == 2020, # add proxy catches from M. Parker shared 12/4/2024
                         0.0475 + 0.0527,
                         0),
         Dead_Catch = Dead_Catch + to_add) |>
  select(-to_add)

albin <- read.csv(here('Data/Raw_not_confidential/yellowtail_rows_from_Albin_et_al_1993.csv'), 
                  skip = 1) %>%
  `names<-`(paste(names(.), slice(., 1))) |>
  slice(-1) |>
  select(-1) |>
  tidyr::pivot_longer(cols = -1, names_to = 'Label', values_to = 'Value') |>
  tidyr::separate_wider_delim(Label, ' ', names = c('County', 'Metric')) |>
  mutate(County = stringr::str_remove(County, '.[:digit:]')) |>
  mutate(County = stringr::str_replace_all(County, '[:punct:]+', '_')) |>
  filter(County != 'Total') |>
  rename(Year = `X.1 Year`) |>
  tidyr::pivot_wider(id_cols = c(Year, County), names_from = Metric, values_from = Value) |>
  mutate(across(Est:CV, as.numeric)) |>
# catch-weighted average  
  group_by(County) |>
  summarise(Est = sum(Est)) |>
  ungroup() |>
  mutate(not_slo = County != 'San_Luis_Obispo',
    pct = Est/sum(Est),
    pct_no_slo = Est/sum(Est * not_slo)) |>
  filter(County == 'Del_Norte_Humboldt')
# no weighting  
  # group_by(Year) |>
  # mutate(not_slo = County != 'San_Luis_Obispo',
  #   pct = Est/sum(Est),
  #   pct_no_slo = Est/sum(Est * not_slo)) |>
  # ungroup() |>
  # filter(County == 'Del_Norte_Humboldt') |>
  # summarise(pct = mean(pct), 
  #           pct_no_slo = mean(pct_no_slo))
# This makes basically no difference.

crfs_ratios <- read.csv(here('Data/Raw_not_confidential/RecFIN_CA_catch_to_2023.csv')) |> 
  filter(RECFIN_SUBREGION_NAME == 'Northern California',
         RECFIN_YEAR <= 2010 ) |> # 6 years is symmetric with # of years in Albin
  # did catch-weighted average for Albin, so similar for CRFS
  group_by(DISTRICT_NAME) |>
  summarise(Catch_mt = sum(SUM_TOTAL_MORTALITY_MT)) |>
  ungroup() |>
  mutate(pct = Catch_mt / sum(Catch_mt)) |>
  filter(grepl('Redwood', DISTRICT_NAME))

# This is pre-filtered to N. CA MRFSS only
ca_mrfss_catch <- read.csv(here('Data/Confidential/Rec/RecFIN_CA_MRFSS.csv')) |>
  arrange(desc(WGT_AB1)) |> 
  group_by(YEAR) |>
  summarise(n_ca_catch_mt = sum(WGT_AB1, na.rm = TRUE)/1000) |> 
  # for MRFSS phase 2, calculate ratio above 40-10 by weighted average of Albin and CRFS ratios
  # weights are the inverse of time to last Albin year, first CRFS year
  mutate(weighted_ratio = (albin$pct / (YEAR - 1986) + crfs_ratios$pct / (2005 - YEAR)) / (1/(YEAR - 1986) + 1/(2005 - YEAR)),
         Dead_Catch = ifelse(YEAR < 1990,
                             n_ca_catch_mt * albin$pct_no_slo,
                             n_ca_catch_mt * weighted_ratio),
         State = 'CA (mt)') |>
  select(-n_ca_catch_mt, -weighted_ratio) |>
  rename(RECFIN_YEAR = YEAR) |>
  filter(RECFIN_YEAR != 1980)

# Interpolate between 3-year average before and after MRFSS break
ca_mrfss_interpolate <- tibble(
  Dead_Catch = seq(from = mean(ca_mrfss_catch$Dead_Catch[ca_mrfss_catch$RECFIN_YEAR %in% 1987:1989]),
                   to = mean(ca_mrfss_catch$Dead_Catch[ca_mrfss_catch$RECFIN_YEAR %in% 1993:1995]),
                   length.out = 5)[-c(1,5)], # index 1 and 5 = before break, after break averages
  RECFIN_YEAR = 1990:1992,
  State = 'CA (mt)')

# Put it all together
bind_rows(or_rec_catch, wa_modern, wa_historical, ca_modern, ca_mrfss_catch, ca_mrfss_interpolate) |>
  tidyr::pivot_wider(names_from = 'State', values_from = 'Dead_Catch', values_fill = 0) |>
  rename(YEAR = 'RECFIN_YEAR') |>
  arrange(YEAR) |>
  knitr::kable(align = 'l', digits = 1)

```

#### Outstanding issues for WA:

1.  There are three values for `RECFIN_WATER_AREA_NAME`: Estuary, Ocean, and Canada. Which should be included? Above table excludes Canada.
2.  2023 has a number of instances where `RECFIN_WEEK` is zero, ~~and one instance where is it missing. In the instance where it is missing, there is no estimate of catch in mt.~~ Is `RECFIN_WEEK` of zero any cause for concern?
3.  Will likely convert the numbers in the historical sport landings to weight in mt. Waiting for rec biodata before this is possible. Will then linearly interpolate between 1967 and 1975.

#### Method for CA MRFSS catches:

From Albin et al. (1993), which covers 1981-1986, calculate two ratios:

1.  Total catch in Del Norte/Humboldt / total catch in all counties
2.  Total catch in Del Norte/Humboldt / total catch in all counties except SLO

From CRFS data for 2005-2010, calculate total catch in Redwoods district / total catch in N. CA sub-region

From MRFSS data, calculate total catch by year in N. CA sub-region

For CA rec catch estimates for the assessment:

-   1980-1989: Multiply total N. CA catch by Albin ratio (2)
-   1993-2004: Multiply total N. CA catch by weighted average of Albin ratio (1) and CRFS ratio. Weights are inverse of time to last Albin year or first CRFS year.
-   1990-1992: Interpolate between average of 1987-1989 and 1993-1995

**Concern**: Catches for 1980-1989 look somewhat high. They exceed rec catches in OR in 1982 and 1983. 1982, in particular, has much higher MRFSS catches in N. CA than any other year.

## Comp Data

### Commercial

Initial length sample sizes after running `PacFIN.Utilities::cleanPacFIN()`:

```{r comm-bio, cache=TRUE}
load(here('Data/Confidential/Commercial/pacfin_12-11-2024/PacFIN.YTRK.bds.11.Dec.2024.RData'))
bds_clean <- PacFIN.Utilities::cleanPacFIN(bds.pacfin, verbose = FALSE) 
bds_clean |>
  filter(state == 'WA' | state == 'OR' | PACFIN_GROUP_PORT_CODE == 'CCA' |
           PACFIN_GROUP_PORT_CODE == 'ERA', geargroup != 'XXX') |> 
  filter(year < 2024) |>
  group_by(state, year) |>
  summarise(n_length = sum(!is.na(length))) |>
  tidyr::pivot_wider(names_from = state, values_from = n_length, values_fill = 0) |>
  rowwise() |>
  mutate(total = OR + WA + CA) |>
  arrange(year) |>
  knitr::kable(align = 'l', digits = 1)

```

Age sample sizes:

```{r comm-ages}
bds_clean |>
  filter(state == 'WA' | state == 'OR' | PACFIN_GROUP_PORT_CODE == 'CCA' |
           PACFIN_GROUP_PORT_CODE == 'ERA') |> 
  filter(year < 2024) |>
  group_by(state, year) |>
  summarise(n_length = sum(!is.na(Age))) |>
  tidyr::pivot_wider(names_from = state, values_from = n_length, values_fill = 0) |>
  rowwise() |>
  mutate(total = OR + WA + CA) |>
  arrange(year) |>
  knitr::kable(align = 'l', digits = 1)
```

Note that California lengths are not yet available for 2023.

While running `PacFIN.Utilities::cleanPacFIN()`, it noted that 20 Washington ages in 1991 were double read, the second reader was not recorded, the first and second ages differed, and no final age was determined.

#### Comparing midwater vs bottom trawl lengths and ages

The length and age distribution associated with the midwater trawl (MDT) code in PacFIN is is very similar to bottom trawl catch (everything else in the TWL gear group). Note that the sample sizes for ages in 2022-2024 are lower than other years, especially midwater in 2022 which only has 14 ages.

```{r pacfin-midwater-vs-bottom-figs}
# create separate geargroup2 column which separates midwater from bottom trawl
# see note at 
# https://github.com/pfmc-assessments/PacFIN.Utilities/issues/69#issuecomment-2499162809
bds_clean <- bds_clean |>
  dplyr::mutate(geargroup2 = ifelse(GRID == "MDT", yes = "MDT", no = geargroup))

# length distributions for bottom trawl vs midwater trawl in recent years
bds_clean |>
  filter(geargroup == "TWL", SAMPLE_YEAR >= 2011) |> # exclude all non-trawl gear and pre-catch-shares years
  ggplot(aes(
    x = lengthcm,
    y = forcats::fct_rev(as.factor(SAMPLE_YEAR)),
    color = as.factor(geargroup2)
    #fill = as.factor(geargroup2)
  )) +
  ggridges::geom_density_ridges(alpha = 0.2) +
  labs(
    x = "Length (cm)",
    y = "Year",
  ) + 
  scale_color_discrete(
    name = "Gear",
    breaks = c("MDT", "TWL"),
    labels = c("Midwater trawl", "Bottom trawl")
  )

# age comps from midwater vs bottom trawl
bds_clean |>
  filter(geargroup == "TWL", !is.na(Age),SAMPLE_YEAR >= 2011) |>
  ggplot(aes(
    x = Age,
    y = forcats::fct_rev(as.factor(SAMPLE_YEAR)),
    color = as.factor(geargroup2)
  )) +
  ggridges::geom_density_ridges(
    alpha = 0.2,
    stat = "binline",
    binwidth = 1
  ) +
  labs(
    x = "Age",
    y = "Year",
  ) +
  scale_color_discrete(
    name = "Gear",
    breaks = c("MDT", "TWL"),
    labels = c("Midwater trawl", "Bottom trawl")
  )

```

### Recreational

VERY tentative length sample sizes. I anticipate this is biased high as I have done no filtering.

```{r recfin-bio}
# recent length data
rec_bio <- read.csv(here("Data/Confidential/rec/RecFIN_Lengths.csv")) |>
  tibble::as_tibble() |>
  filter(STATE_NAME == "OREGON" | STATE_NAME == "WASHINGTON" | grepl("REDWOOD", RECFIN_PORT_NAME))

# or mrfss data
or_mrfss <- read.csv(here("Data/Confidential/rec/MRFSS_BIO_2025 CYCLE_433.csv")) |>
  tibble::as_tibble()

or_mrfss_smry <- or_mrfss |> 
  filter(Length_Flag == 'measured') |>
  group_by(Year) |> 
  summarise(n_length = n()) |>
  mutate(STATE_NAME = 'OR (MRFSS)') |>
  tidyr::pivot_wider(names_from = STATE_NAME, values_from = n_length)

# ca/wa mrfss data
ca_wa_mrfss <- read.csv(here("Data/Confidential/rec/MRFSS_lengths_CA_WA.csv")) |>
  as_tibble() |> 
  filter(ST_NAME == 'Washington' | (ST_NAME == 'California' & (CNTY == 15 | CNTY == 23))) |> # 15 = Del Norte, 23 = Humboldt, FIPS codes
  filter(T_LEN %% 1 == 0 | LNGTH %% 1 == 0) # I believe this will filter to measured lengths

ca_wa_mrfss_smry <- ca_wa_mrfss |>
  group_by(YEAR, ST_NAME) |>
  summarise(n_length = n()) |>
  ungroup() |>
  mutate(state = case_when(ST_NAME == 'California' ~ 'CA (MRFSS)',
                           ST_NAME == 'Washington' ~ 'WA (MRFSS)')) |>
  tidyr::pivot_wider(names_from = state, values_from = n_length, id_cols = YEAR, values_fill = 0) |>
  rename(Year = YEAR)

rec_bio |>
  ggplot() +
  geom_density(aes(x = RECFIN_LENGTH_MM, col = STATE_NAME, fill = IS_RETAINED), 
               linewidth = 1, alpha = 0.2) +
  scale_fill_manual(values = c('red', 'blue')) +
  labs('RecFIN length compositions by state and disposition') +
  viridis::scale_color_viridis(discrete = TRUE) 

# Note: 1993 uses total length. 1994 onward uses fork length.
rec_bio |>
  filter(!is.na(RECFIN_LENGTH_MM)) |> 
  mutate(state = case_when(STATE_NAME == 'WASHINGTON' ~'WA',
                           STATE_NAME == 'OREGON' ~ 'OR',
                           STATE_NAME == 'CALIFORNIA' ~ 'CA')) |>
  group_by(RECFIN_YEAR, state, IS_RETAINED) |>
  summarize(n_length = n()) |>
  rename(Year = RECFIN_YEAR) |> 
  tidyr::pivot_wider(names_from = c(state, IS_RETAINED), values_from = n_length, 
                     values_fill = 0) |> 
  full_join(or_mrfss_smry) |>
  full_join(ca_wa_mrfss_smry) |>
  arrange(Year) |> 
  mutate(across(everything(), ~tidyr::replace_na(.x, 0))) |>
  knitr::kable(align = 'l')
```

Retained fish tend to be larger than released fish. However, there are very few released fish. Washington has no measured released fish in RecFIN. Between Oregon and California, `r filter(rec_bio, STATE_NAME != 'WASHINGTON') %>% {100 * with(., sum(IS_RETAINED == 'RETAINED'))/nrow(.)} |> round(1)`% of lengths are for retained fish. Some fraction of those released fish is assumed to have survived, which would skew the ratio even more towards retained fish.

Options:

1.  Exclude released fish from comps
2.  Lump released and retained fish together
3.  Model a retention curve

The fish in Washington also look slightly larger than those in Oregon and California. This difference is more pronounced than it is in survey data, indicating a possible selectivity effect.

I am unsure how to filter MRFSS data to measured lengths for WA and CA. The counts in the table above filters lengths to whole numbers (mm).

### At-Sea

```{r ashop-bio}
ashop_lengths_old <- readxl::read_excel(
  here("Data/Confidential/ASHOP/Oken_YLT_Length data_1976-2023_102824_ASHOP.xlsx"), 
  sheet = "YLT_Length data 1976-1989")
ashop_lengths_new <- suppressWarnings(
  readxl::read_excel(here("Data/Confidential/ASHOP/Oken_YLT_Length data_1976-2023_102824_ASHOP.xlsx"), 
                     sheet = "YLT_Length data1990-2023") # warning is about converting text to numeric
)

bind_rows(ashop_lengths_old, ashop_lengths_new) |>
  group_by(YEAR) |>
  summarise(n_length = sum(FREQUENCY)) |>
  knitr::kable(align = 'l')
```

Figure of length frequencies in at-sea hake fishery for prioritizing which years to age.

```{r ashop-bio-fig}
ashop_lengths_new |> 
  tidyr::uncount(FREQUENCY) |>
  left_join(ashop_catch, by = 'YEAR') |> 
  mutate(catch_mt = EXPANDED_SumOfEXTRAPOLATED_2SECTOR_NUMBER / 1000) |>
  ggplot() +
  ggridges::geom_density_ridges(aes(x = LENGTH, y = YEAR, group = YEAR, 
                                    fill = catch_mt), alpha = 0.5) +
  xlim(30, 65) +
  viridis::scale_fill_viridis()
```

## Survey data

STAT is working on it!

```{r survey, eval=FALSE}
yt_survey_bio <- nwfscSurvey::pull_bio(common_name = 'yellowtail rockfish', survey = 'NWFSC.Combo') 

yt_n_survey_bio <- filter(yt_survey_bio, Latitude_dd > 40 + 1/6)

yt_tri_bio <- yt_survey_bio <- nwfscSurvey::pull_bio(common_name = 'yellowtail rockfish', survey = 'Triennial') 

yt_n_tri_bio <- purrr::map(yt_tri_bio, \(dat) filter(dat, Latitude_dd > 40 + 1/6))


# looking at how growth varies over space and time
# clear break point in selectivity between age 5 and 6.
filter(yt_n_survey_bio, Age_years <= 20, Age_years >= 6) |>
ggplot() +
  geom_point(aes(x = Year, y = Length_cm, col = Age_years), alpha = 0.2) +
  stat_smooth(aes(x = Year, y = Length_cm, group = Age_years, col = Age_years), se = FALSE)
# possible decrease in length at age of older fish in last 4 years of data. TBD with 8 more years!

filter(yt_survey_bio, Age_years <= 20, Age_years >= 6) |>
ggplot() +
  geom_point(aes(x = Latitude_dd, y = Length_cm, col = Age_years), alpha = 0.2) +
  stat_smooth(aes(x = Latitude_dd, y = Length_cm, group = Age_years, col = Age_years), se = FALSE, method = 'lm')
# Larger max size farther north (consistent with theory)

yt_survey_bio |>
  ggplot(aes(x = Latitude_dd, y = Age_years)) +
  geom_point(alpha = 0.1) +
  stat_smooth(se = FALSE)
# Latitudinal age structure: below 43 degrees, avg age ~10, above 45 degrees, avg age ~15

ggplot(yt_n_survey_bio) +
  geom_point(aes(x = Age_years, y = Length_cm, col = Sex), alpha = 0.1)
# Large fish female, old fish male prevails, but not as notable as with canary.

yt_n_survey_bio |>
  group_by(Age_years) |>
  summarise(pct_f = sum(Sex == 'F')/n(),
            se = sqrt(pct_f * (1-pct_f) / n())) |>
  ggplot() +
  geom_point(aes(x = Age_years, y = pct_f)) +
  geom_errorbar(aes(x = Age_years, ymin = pct_f - se, ymax = pct_f + se))

laa_by_lat_lm <- lm(Length_cm ~ I(Latitude_dd-mean(Latitude_dd))*factor(Age_years), 
                                   data = yt_n_survey_bio, 
                      subset = Age_years < 20 & Age_years >= 6)

laa_by_age <- lm(Length_cm ~ factor(Age_years), data = yt_n_survey_bio, 
                      subset = Age_years < 20 & Age_years >= 6)

W_L_pars <- yt_n_survey_bio |>
  dplyr::mutate(Sex = 'B') |> # this will make it so a single curve is fit to all sexes, in addition to sex-specific curves
  dplyr::bind_rows(yt_n_survey_bio) |>
  dplyr::filter(Sex %in% c('F', 'M', 'B')) |>
  tidyr::nest(data = -Sex) |> 
                                         # Fit model
  dplyr::mutate(fit = purrr::map(data, ~ lm(log(Weight) ~ log(Length_cm), data = .)),
                tidied = purrr::map(fit, broom::tidy),
                # Transform W-L parameters, account for lognormal bias
                out = purrr::map2(tidied, fit, function(.x, .y) {
                  sd_res <- sigma(.y)
                  .x |>
                    dplyr::mutate(term = c('A', 'B'),
                                  median = ifelse(term == 'A', exp(estimate), estimate),
                                  mean = ifelse(term == 'A', median * exp(0.5 * sd_res^2),
                                                median)) |>
                    dplyr::select(term, mean)
                }),
                n = purrr::map(fit, ~ length(resid(.)))) |>
  tidyr::unnest(c(out, n)) |>
  dplyr::select(Sex, term, mean, n) |>
  tidyr::pivot_wider(names_from = term, values_from = mean)

write.csv(W_L_pars, here('Data/Processed/W_L_pars.csv'), row.names = FALSE)

### Megan this is where I look at time-varying weight-length
W_L_pars |>
  dplyr::mutate(out.dfr = purrr::map2(A, B, ~ dplyr::tibble(len = 1:max(yt_n_survey_bio$Length_cm, na.rm = TRUE), 
                                                            wgt = .x*len^.y))) |>
  tidyr::unnest(out.dfr) |>
  dplyr::filter(Sex != 'B') |>
  ggplot() +
  geom_point(aes(x = Length_cm, y = Weight, col = Sex), alpha = 0.15, 
             data = dplyr::filter(yt_n_survey_bio, Sex != 'U')) +
  geom_line(aes(x = len, y = wgt, col = Sex), linewidth = 1) +
  labs(x = 'Length (cm)', y = 'Weight') +
  scale_color_manual(values = c('F' = 'red', 'M' = 'blue')) +
  facet_wrap(~ Year) 

yt_n_survey_bio |>
  dplyr::filter(!is.na(Length_cm), !is.na(Weight_kg)) %>%
  broom::augment(lm(log(Weight_kg) ~ log(Length_cm), data = .),
                 .) |>
  group_by(Year) |>
  summarise(mean_resid = mean(.resid)) |>
  ggplot() +
  geom_line(aes(x = Year, y = mean_resid)) +
  geom_hline(yintercept = 0)

```
