---
title: "Data summary"
date: today
format: 
  html:
    toc: true
    output-file: "index"
editor: visual
---

```{r opts, echo = FALSE, include = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(here)
library(dplyr)
library(ggplot2)
theme_set(theme_classic())
```

This documents data streams for use in the Northern Yellowtail Rockfish stock assessment. These data are NOT final and have NOT been fully QA/QC'ed! They are here for communication with the STAT and other collaborators. It is not official communication of the National Oceanic and Atmospheric Administration or the United States Department of Commerce.

## Landings

### Commercial landings

Some summary figures:

```{r pacfin-catch, cache=TRUE}
load(here('data/confidential/commercial/pacfin-02-13-2025/PacFIN.YTRK.CompFT.13.Feb.2025.RData'))
# I have checked and LANDING_YEAR = PACFIN_YEAR for all rows.

yt_n_catch_pacfin <- catch.pacfin |>
  filter(
    AGENCY_CODE == 'W' | AGENCY_CODE == 'O' | COUNTY_NAME == 'DEL NORTE' | COUNTY_NAME == 'HUMBOLDT', # OR, WA, N. CA
    LANDING_YEAR < 2025
  )

# OR landings time series
or_comm_catch <- read.csv(here("Data/Confidential/commercial/Oregon Commercial landings_433_2024.csv")) |>
  tibble::as_tibble() |>
  group_by(YEAR) |>
  summarise(catch_mt = sum(TOTAL)) |>
  mutate(AGENCY_CODE = 'O')

# WA URCK/UPOP reconstruction, use 1981-2000
wa_urck <- read.csv(here('Data/Confidential/Commercial/WA_URCK_UPOP_recon_1981-2016.csv')) |>
  filter(Species_AfterComps %in% c('YTRK', 'YTR1'), 
         Year < 2001) |> 
  group_by(Year) |>
  summarise(catch_mt = sum(RoundPounds_AfterComps) * 0.453592 / 1000) |>
  mutate(AGENCY_CODE = 'W') |>
  rename(YEAR = Year)

# WA historical reconstruction
wa_hist <- read.csv(here('Data/Confidential/Commercial/SpeciesSumOutput2_2017.csv')) |> 
  filter(SPID == 'YTRK' | SPID == 'YTR1') |> 
  group_by(Year) |>
   summarise(catch_mt = #format(
    sum(SpeciesPounds, na.rm = TRUE) * 0.453592 / 1000, 
    #scientific = FALSE),
    ) |>
  filter(Year < 1981) |>
  rename(YEAR = Year) |>
  mutate(AGENCY_CODE = 'W')

# CA historical
calcom_full <- readxl::read_excel(
  here('Data/Confidential/Commercial/Yellowtail Rockfish California Catch Reconstructions 2024-12-18.xlsx'), 
  sheet = 'CA COMM. 1969-1980', skip = 3
) |>
  select(YEAR:SPECIES_GRP) 

calcom <- calcom_full |>
  filter(PORT_COMPLEX %in% c('ERK', 'CRS')) |>
  group_by(YEAR) |>
  summarise(catch_mt = sum(POUNDS) * 0.453592 / 1000) |>
  mutate(AGENCY_CODE = 'C')

calcom_ratio <- calcom_full |>
  filter(PORT_COMPLEX %in% c('ERK', 'CRS', 'BRG'), # filter to ralston region 1,
         YEAR < 1974) |> # ratio over first 5 years of CALCOM?
  mutate(is_n_40_10 = PORT_COMPLEX %in% c('ERK', 'CRS')) |>
  group_by(YEAR) |>
  summarise(region_1 = sum(POUNDS),
            n_40_10 = sum(POUNDS * is_n_40_10)) |>
  ungroup() |>
  summarise(pct_n_40_10 = sum(n_40_10) / sum(region_1)) # catch-weighted avg, like rec ratios

ralston_comm_or <- readxl::read_excel(
  here('Data/Confidential/Commercial/Yellowtail Rockfish California Catch Reconstructions 2024-12-18.xlsx'), 
  sheet = 'RALSTON ET AL. COMM. OR waters', range = 'A4:B25'
) |>
  rename(YEAR = Year) # use all catches, clearly are north of 40-10

ralston_comm <- readxl::read_excel(
  here('Data/Confidential/Commercial/Yellowtail Rockfish California Catch Reconstructions 2024-12-18.xlsx'), 
  sheet = 'RALSTON ET AL. 2010 COMM.', skip = 5
) |>
  select(year:source) |>
  rename(region_caught = `region_caught...3`, YEAR = year) |>
  filter(region_caught == 2) |> # region 2 = Crescent City, Eureka, Fort Bragg
  group_by(YEAR) |>
  summarise(catch_mt = calcom_ratio$pct_n_40_10 * sum(pounds) * 0.453592 / 1000) |>
  mutate(AGENCY_CODE = 'C') |>
  left_join(ralston_comm_or) |>
  mutate(Oregon = tidyr::replace_na(Oregon, 0),
         catch_mt = catch_mt + Oregon) |>
  select(-Oregon)

# Foreign
foreign <- read.csv(here('Data/raw_not_confidential/foreign_catch.csv')) |>
  mutate(catch_mt = UVAN + COL + EUR,
         AGENCY_CODE = 'Foreign') |> # MON/EUR split is ~Medocino
  select(YEAR = year, catch_mt, AGENCY_CODE)

# Put it all together
comm_draft_landings <- yt_n_catch_pacfin |> 
  filter(AGENCY_CODE != 'O',
         AGENCY_CODE != 'W' | PACFIN_YEAR >= 2001
         ) |> 
  group_by(PACFIN_YEAR, AGENCY_CODE)|>
  summarise(catch_mt = sum(ROUND_WEIGHT_MTONS)) |>
  rename(YEAR = PACFIN_YEAR) |>
  bind_rows(
    or_comm_catch,
    wa_urck,
    wa_hist,
    calcom,
    ralston_comm,
    foreign
  )|> 
  group_by(YEAR, AGENCY_CODE) |>
  summarise(catch_mt = sum(catch_mt))

# landings by state
comm_draft_landings |>
  ggplot() +
  geom_col(aes(x = YEAR, y = catch_mt, 
               fill = factor(AGENCY_CODE, levels = c('Foreign', 'C', 'O', 'W')))) +
  labs(title = 'Commercial landings through 2023 by state',
       fill = 'State') +
  viridis::scale_fill_viridis(discrete = TRUE)

# landings by gear type
yt_n_catch_pacfin |>
  group_by(PACFIN_GROUP_GEAR_CODE, LANDING_YEAR) |>
  summarise(catch_mt = sum(ROUND_WEIGHT_MTONS)) |>
  ggplot() +
  geom_col(aes(x = LANDING_YEAR, y = catch_mt, fill = factor(PACFIN_GROUP_GEAR_CODE, levels = c('TWL', 'MSC', 'NET', 'POT', 'TLS', 'TWS', 'HKL')))) +
  ggtitle('Commercial landings through 2023 by gear') +
  labs(fill = 'PacFIN gear group', x = 'YEAR') +
  viridis::scale_fill_viridis(discrete = TRUE)

# total catch by gear over time with midwater trawl separated
yt_n_catch_pacfin |>
  mutate(geargroup2 = ifelse(PACFIN_GEAR_CODE == "MDT", yes = "MDT", no = PACFIN_GROUP_GEAR_CODE)) |> # split midwater trawl as MDT
  group_by(geargroup2, LANDING_YEAR) |>
  summarise(catch_mt = sum(ROUND_WEIGHT_MTONS)) |>
  ggplot() +
  geom_col(aes(x = LANDING_YEAR, y = catch_mt, fill = factor(geargroup2, levels = c("TWL", "MDT", "MSC", "NET", "POT", "TLS", "TWS", "HKL")))) +
  ggtitle("Commercial landings through 2023 by gear with midwater trawl separated") +
  labs(fill = "PacFIN gear group\n(MDT = midwater trawl)", x = 'YEAR') #+
  # viridis::scale_fill_viridis(discrete = TRUE) # colors were hard to see in viridis

# compare 2017 landings to current landings, by state

# 2017 assessment landings
comm2017 <- read.csv(here("Data/Raw_not_confidential/commercial_catch_2017.csv")) |> 
  as_tibble() |>
  tidyr::replace_na(list(Mirick.reconstructed.POP1.URCK = 0)) |>
  mutate(O = OR.Recent..MT. + Mirick.reconstructed.POP1.URCK + OR.Hist..MT.,
         W = as.numeric(stringr::str_remove(WA, ',')),
         C = CA.North..MT. + CA.North.Hist..MT.) |> 
  select(Year, W, C, O) |>
  # filter(Year >= 1981) |>
  tidyr::pivot_longer(-Year, names_to = 'AGENCY_CODE', values_to = 'catch_mt') |>
  mutate(model = '2017') 

comm_draft_landings |>
  rename(Year = YEAR) |>
  mutate(model = 'current') |>
  bind_rows(comm2017) |> 
  ggplot() +
  geom_line(aes(x = Year, y = catch_mt, col = AGENCY_CODE, linetype = model), linewidth = 1) +
  viridis::scale_color_viridis(discrete = TRUE) +
  labs(title = 'Comparing commercial landings in 2017 model vs current', x = 'YEAR')
```

Table of commercial landings by state, 1981 onward.

```{r comm-catch-tbl}
catch_wide <- comm_draft_landings |>
  mutate(State = case_when(AGENCY_CODE == 'C' ~ 'CA',
                           AGENCY_CODE == 'O' ~ 'OR',
                           AGENCY_CODE == 'W' ~ 'WA',
                           TRUE ~ AGENCY_CODE)) |>
  select(-AGENCY_CODE) |>
  tidyr::pivot_wider(names_from = State, values_from = catch_mt, values_fill = 0) |>
  relocate(Foreign, .after = WA)

# add in pre-1981 WA catches from 2017 model, save for PacFIN.Utilities
filter(comm2017, AGENCY_CODE == 'W') |>
  select(YEAR = Year, catch_mt) |>
  right_join(catch_wide) |>
  mutate(WA = ifelse(YEAR < 1981, WA + catch_mt, WA)) |>
  select(-catch_mt) |>
  saveRDS(file = here('Data/processed/catch_wide.rds'))

catch_wide |>
  knitr::kable(align = 'l', digits = 1)
```

Note that the 2017 assessment did not include foreign landings. This foreign reconstruction is from Rogers (2003).

WDFW has alerted the STAT these do not include all tribal catches in recent years. 1981-2000 are from the UPOP/URCK reconstruction, summing catches for YTRK and YTR1. 2001 onward comes from PacFIN

Oregon landings were provided directly to the STAT from ODFW and come from PacFIN and a UPOP/URCK reconstruction.

California landings are for catch landed into Del Norte and Humboldt counties only. Data sources are:

-   Ralston et al. (2010) + supplementary catch from OR waters: 1916 - 1968
-   CALCOM: 1969 - 1980
-   PacFIN: 1981 - present

In the Ralston et al. (2010) reconstruction, the northernmost region (region 2) includes Crescent City, Eureka AND Fort Bragg port area groups. Catch in the Crescent City and Eureka port area groups (i.e., Del Norte and Humboldt counties) is estimated based on the fraction of catch in Crescent City and Eureka divided by catch in all of region 2 during the first five years of CALCOM. The vast majority of the catch is in the two northern port areas (`r round(calcom_ratio$pct_n_40_10 * 100, 0)`%). All supplementary catches in the Ralston reconstruction caught off the coast of Oregon, but landed into California are included.

### At-Sea landings

```{r ashop-catch}
ashop_catch <- bind_rows(
  readxl::read_excel(
    here("Data/Confidential/ASHOP/Oken_YLT_Catch data_1976-2023_102824_ASHOP.xlsx"), 
    sheet = 'Catch Summary Table'),
  readxl::read_excel(
    here("Data/Confidential/ASHOP/Oken_YLT_Catch data_2024_020425.xlsx"), 
    sheet = '2024_Summary Table')
  )|>
  mutate(catch_mt = EXPANDED_SumOfEXTRAPOLATED_2SECTOR_WEIGHT_KG / 1000) 

# compare to 2017
dat2017 <- r4ss::SS_readdat(here('Model_Runs/1.02_base_2017_3.30.23/YTRK.NORTH.data.ss'))

ashop2017 <- dat2017$catch |>
  filter(fleet == 2) |> 
  select(Year = year, catch_mt = catch) |>
  mutate(model = '2017')

ashop_catch |>
  select(Year = YEAR, catch_mt) |> 
  mutate(model = 'current') |>
  bind_rows(ashop2017) |> 
  ggplot() +
  geom_line(aes(x = Year, y = catch_mt, col = factor(model, levels = c('current', '2017'))), 
                linewidth = 1) +
  viridis::scale_color_viridis(discrete = TRUE) +
  labs(title = 'Comparing ASHOP landings in 2017 model vs current', col = 'Data source')
# Matches.

ashop_catch |>
  select(YEAR, catch_mt) |>
  knitr::kable(align = 'l', digits = 1)
```

### Recreational landings

```{r rec-catch-modern}
# WASHINGTON
wa_modern <- read.csv(here('Data/Confidential/Rec/CTE501-WASHINGTON-1990---2024.csv')) |> 
  filter(RECFIN_WATER_AREA_NAME != 'CANADA', 
         RECFIN_CATCH_AREA_NAME != 'SEKIU AND PILLAR POINT') |> 
  tibble::as_tibble() |> 
  group_by(RECFIN_YEAR) |> 
  summarise(Dead_Catch = sum(TOTAL_MORTALITY_MT)) |>
  mutate(State = 'WA (mt)')

wa_sport_bio <- read.csv(here('Data/Confidential/Rec/ytrk_sport_biodata.csv'))

wa_hist_avg_len <- wa_sport_bio |> 
  filter(sample_year <= 1989) |> # after 1989 WA rec catches available in weight
  summarise(avg_len = mean(fish_length_cm, na.rm = TRUE), 
            N = sum(!is.na(fish_length_cm)))
# 48 total samples across 3 years, lump it all together
# next samples are in 1995, so don't bother borrowing from early future years

# could pull these from the triennial survey instead to be more temporally-appropriate...
W_L_pars_unsexed <- read.csv(here('Data/Processed/W_L_pars.csv')) |>
  filter(sex == 'all')

wa_historical <- read.csv(here('Data/Raw_not_confidential/WA_historical_rec.csv')) |> 
  tibble::as_tibble() |>
  filter(AREA %in% 1:4) |> # these are marine areas, per T. Tsou on 12/10/24 in meeting notes
  group_by(RECFIN_YEAR) |>
  summarise(`WA (num)` = sum(RETAINED_NUM)) |>
  bind_rows(
    # data originally emailed by T. Tsou 1/28/25.
    # corrected by T. Tsou and F. Caltabellotta 2/18/25
    # Bargmann, G.G. 1977. The recreational hook and line fishery for marine fish in Washington 196801973. Washington Department of Fisheries, Progress Report No. 33.
    {read.csv(here("Data/Raw_not_confidential/WA_historical_rec_addition.csv")) |>
        group_by(Year) |>
        summarise(`WA (num)` = sum(Total)) |>
        rename(RECFIN_YEAR = Year)
    }
  ) |>
  arrange(RECFIN_YEAR) |>
  mutate(`WA (mt)` = (W_L_pars_unsexed$A * wa_hist_avg_len$avg_len ^
                        W_L_pars_unsexed$B) * `WA (num)`
  )

wa_historical_interpolate <- tibble(
  Dead_Catch = c(mean(wa_historical$`WA (mt)`[wa_historical$RECFIN_YEAR %in% c(1969, 1970, 1972, 1973)]),
                 mean(wa_historical$`WA (mt)`[wa_historical$RECFIN_YEAR %in% c(1972, 1973, 1975, 1976)])),
  RECFIN_YEAR = c(1971, 1974),
  State = 'WA (mt)')


# OREGON
or_rec_catch <- read.csv(here("Data/Confidential/Rec/Oregon Recreational landings_433_2024.csv")) |>
  tibble::as_tibble() |>
  mutate(State = 'OR (mt)') |>
  select(RECFIN_YEAR = Year, Dead_Catch = Total_MT, State)

# CALIFORNIA
urck_ca_2020 <- read.csv(here('Data/Raw_not_confidential/genus_allocate_2025_assessments.csv')) |>
  select(yellowtail_num, yellowtail_kg, year, mode, orig_allocated, district, district_name) |>
  filter(grepl('REDWOOD', district_name),
         orig_allocated == 'allocated',
         yellowtail_num > 0) |>
  summarise(catch_mt = sum(yellowtail_kg) / 1000)
# Note that these are available for 2020 and 2021, but the amount to add in 2021 = 0.

proxy_ca_2020 <- readxl::read_excel(here('Data/Raw_not_confidential/CDFWRec_YellowtailRF N 40 10_AvgProxyValuesApr-Jun2020.xlsx')) |>
  summarise(catch_mt = sum(`Proxy Average Value (mt)`))

ca_modern <- read.csv(here('Data/Raw_not_confidential/CTE001-California-1990---2024.csv')) |>
  filter(grepl("Redwood", DISTRICT_NAME)) |>
  tibble::as_tibble() |>
  group_by(RECFIN_YEAR) |>
  summarise(Dead_Catch = sum(SUM_TOTAL_MORTALITY_MT)) |>
  mutate(State = 'CA (mt)',
         to_add = ifelse(RECFIN_YEAR == 2020, # 
                         proxy_ca_2020$catch_mt + # from Melanie Parker 
                           urck_ca_2020$catch_mt, # from Julia Coates
                         0),
         Dead_Catch = Dead_Catch + to_add) |>
  select(-to_add)

albin <- read.csv(here('Data/Raw_not_confidential/yellowtail_rows_from_Albin_et_al_1993.csv'), 
                  skip = 1) %>%
  `names<-`(paste(names(.), slice(., 1))) |>
  slice(-1) |>
  select(-1) |>
  tidyr::pivot_longer(cols = -1, names_to = 'Label', values_to = 'Value') |>
  tidyr::separate_wider_delim(Label, ' ', names = c('County', 'Metric')) |>
  mutate(County = stringr::str_remove(County, '.[:digit:]')) |>
  mutate(County = stringr::str_replace_all(County, '[:punct:]+', '_')) |>
  filter(County != 'Total') |>
  rename(Year = `X.1 Year`) |>
  tidyr::pivot_wider(id_cols = c(Year, County), names_from = Metric, values_from = Value) |>
  mutate(across(Est:CV, as.numeric)) |>
# catch-weighted average  
  group_by(County) |>
  summarise(Est = sum(Est)) |>
  ungroup() |>
  mutate(not_slo = County != 'San_Luis_Obispo',
    pct = Est/sum(Est),
    pct_no_slo = Est/sum(Est * not_slo)) |>
  filter(County == 'Del_Norte_Humboldt')
# no weighting  
  # group_by(Year) |>
  # mutate(not_slo = County != 'San_Luis_Obispo',
  #   pct = Est/sum(Est),
  #   pct_no_slo = Est/sum(Est * not_slo)) |>
  # ungroup() |>
  # filter(County == 'Del_Norte_Humboldt') |>
  # summarise(pct = mean(pct), 
  #           pct_no_slo = mean(pct_no_slo))
# This makes basically no difference.

crfs_ratios <- read.csv(here('Data/Raw_not_confidential/RecFIN_CA_catch_to_2023.csv')) |> 
  filter(RECFIN_SUBREGION_NAME == 'Northern California',
         RECFIN_YEAR <= 2010 ) |> # 6 years is symmetric with # of years in Albin
  # did catch-weighted average for Albin, so similar for CRFS
  group_by(DISTRICT_NAME) |>
  summarise(Catch_mt = sum(SUM_TOTAL_MORTALITY_MT)) |>
  ungroup() |>
  mutate(pct = Catch_mt / sum(Catch_mt)) |>
  filter(grepl('Redwood', DISTRICT_NAME))

# This is pre-filtered to N. CA MRFSS only
ca_mrfss_catch <- read.csv(here('Data/Confidential/Rec/RecFIN_CA_MRFSS.csv')) |>
  arrange(desc(WGT_AB1)) |> 
  group_by(YEAR) |>
  summarise(n_ca_catch_mt = sum(WGT_AB1, na.rm = TRUE)/1000) |> 
  # for MRFSS phase 2, calculate ratio above 40-10 by weighted average of Albin and CRFS ratios
  # weights are the inverse of time to last Albin year, first CRFS year
  mutate(weighted_ratio = (albin$pct / (YEAR - 1986) + crfs_ratios$pct / (2005 - YEAR)) / (1/(YEAR - 1986) + 1/(2005 - YEAR)),
         Dead_Catch = ifelse(YEAR < 1990,
                             n_ca_catch_mt * albin$pct_no_slo,
                             n_ca_catch_mt * weighted_ratio),
         State = 'CA (mt)') |>
  select(-n_ca_catch_mt, -weighted_ratio) |>
  rename(RECFIN_YEAR = YEAR) |>
  filter(RECFIN_YEAR != 1980)

# Interpolate between 3-year average before and after MRFSS break
ca_mrfss_interpolate <- tibble(
  Dead_Catch = seq(from = mean(ca_mrfss_catch$Dead_Catch[ca_mrfss_catch$RECFIN_YEAR %in% 1987:1989]),
                   to = mean(ca_mrfss_catch$Dead_Catch[ca_mrfss_catch$RECFIN_YEAR %in% 1993:1995]),
                   length.out = 5)[-c(1,5)], # index 1 and 5 = before break, after break averages
  RECFIN_YEAR = 1990:1992,
  State = 'CA (mt)')

# Ralston reconstruction
ralston_rec <- readxl::read_excel(
  here('Data/Confidential/Commercial/Yellowtail Rockfish California Catch Reconstructions 2024-12-18.xlsx'), 
  sheet = 'RALSTON ET AL. REC CA "NORTH"', skip = 12
) |> 
  filter(Units == 'pounds') |>
  group_by(Year) |>
  summarise(catch_mt_n_ca = sum(YTRK) * 0.453592 / 1000) |>
  mutate(Dead_Catch = catch_mt_n_ca * albin$pct,
         State = 'CA (mt)') |>
  select(-catch_mt_n_ca) |>
  rename(RECFIN_YEAR = Year)

# Put it all together
rec_landings <- bind_rows(
  or_rec_catch, 
  wa_modern, 
  tidyr::pivot_longer(wa_historical, cols = -RECFIN_YEAR, names_to = 'State', values_to = 'Dead_Catch'),
  wa_historical_interpolate, 
  ca_modern, 
  ca_mrfss_catch, 
  ca_mrfss_interpolate,
  ralston_rec
  ) 

# rec_landings |>
#   filter(State != 'WA (num)', State != 'WA (mt)') |>
#   group_by(RECFIN_YEAR) |>
#   summarise(Dead_Catch = sum(Dead_Catch)) |>
#   mutate(model = 'current') |>
#   bind_rows({
#     filter(dat2017$catch, fleet == 3) |>
#       mutate(fleet = 'OR/CA',
#              model = '2017') |>
#       select(RECFIN_YEAR = year, Dead_Catch = catch, fleet, model)
#   }) |>
#   ggplot() +
#   geom_line(aes(x = RECFIN_YEAR, y = Dead_Catch, linetype = model),
#             linewidth = 1)
# This is bizarre, it is as if WA was actually entered in mt, even though it is specified in numbers.

rec_landings |>
  tidyr::pivot_wider(names_from = 'State', values_from = 'Dead_Catch', values_fill = 0) |>
  rename(YEAR = 'RECFIN_YEAR') |>
  arrange(YEAR) |>
  knitr::kable(align = 'l', digits = 1)

```

#### Method for converting historical WA catches from numbers to weight

We are planning to use WA (mt) for all years, but show WA (num) to compare with raw data.

From WA sport biodata, calculate average length of samples collected prior to 1990. This included 48 samples from 1979, 1981, and 1982. The next available samples are in 1995, so we did not use length data from samples in years shortly after the historical reconstruction applies.

Calculate average weight using the unsexed version of the weight-length relationship calculated from WCGBTS data.

Catches in 1971 and 1974 are not available, so are calculated as the average of the two previous and two subsequent years.

#### Method for CA MRFSS catches:

From Albin et al. (1993), which covers 1981-1986, calculate two ratios:

1.  Total catch in Del Norte/Humboldt / total catch in all counties
2.  Total catch in Del Norte/Humboldt / total catch in all counties except SLO

From CRFS data for 2005-2010, calculate total catch in Redwoods district / total catch in N. CA sub-region

From MRFSS data, calculate total catch by year in N. CA sub-region

For CA rec catch estimates for the assessment:

-   1980-1989: Multiply total N. CA catch by Albin ratio (2)
-   1993-2004: Multiply total N. CA catch by weighted average of Albin ratio (1) and CRFS ratio. Weights are inverse of time to last Albin year or first CRFS year.
-   1990-1992: Interpolate between average of 1987-1989 and 1993-1995

In addition, Albin ratio (1) is used to calculate what fraction of N. CA catches from the Ralston recreational reconstruction are in the assessment area.

```{r ss3-landings}
rec_landings_ss3 <- rec_landings |>
  filter(State != 'WA (num)') |>
  group_by(RECFIN_YEAR) |>
  summarise(catch = sum(Dead_Catch)) |>
  rename(YEAR = RECFIN_YEAR) 

comm_landings_ss3 <- comm_draft_landings |> 
  group_by(YEAR) |>
  summarise(catch = sum(catch_mt))

ss3_landings <- bind_rows(
  list(
    comm_landings_ss3,
    select(ashop_catch, YEAR, catch = catch_mt),
    rec_landings_ss3
  ), .id = 'fleet') |>
  mutate(seas = 1, catch_se = 0.05) |>
  rename(year = YEAR) |>
  select(names(dat2017$catch)) |>
  as.data.frame()

ss3_landings |>
  saveRDS(file = here('Data/Processed/ss3_landings_2023.rds'))
```

## Comp Data

### Commercial

Initial length sample sizes after running `PacFIN.Utilities::cleanPacFIN()`:

```{r comm-bio, cache=TRUE}
load(here('Data/Confidential/Commercial/pacfin-02-13-2025/PacFIN.YTRK.bds.13.Feb.2025.RData'))
bds_clean <- pacfintools::cleanPacFIN(bds.pacfin, keep_age_method = c('B', 'S'), verbose = FALSE) 

bds_clean |>
  filter(state == 'WA' | state == 'OR' | PACFIN_GROUP_PORT_CODE == 'CCA' |
           PACFIN_GROUP_PORT_CODE == 'ERA', geargroup != 'XXX') |> 
  filter(year < 2025) |>
  group_by(state, year) |>
  summarise(n_length = sum(!is.na(length))) |>
  tidyr::pivot_wider(names_from = state, values_from = n_length, values_fill = 0) |>
  rowwise() |>
  mutate(total = OR + WA + CA) |>
  arrange(year) |>
  knitr::kable(align = 'l', digits = 1)

```

Age sample sizes:

```{r comm-ages}
bds_clean |>
  filter(state == 'WA' | state == 'OR' | PACFIN_GROUP_PORT_CODE == 'CCA' |
           PACFIN_GROUP_PORT_CODE == 'ERA') |> 
  filter(year < 2025) |>
  group_by(state, year) |>
  summarise(n_length = sum(!is.na(Age))) |>
  tidyr::pivot_wider(names_from = state, values_from = n_length, values_fill = 0) |>
  rowwise() |>
  mutate(total = OR + WA + CA) |>
  arrange(year) |>
  knitr::kable(align = 'l', digits = 1)
```

#### Comparing midwater vs bottom trawl lengths and ages

The length and age distribution associated with the midwater trawl (MDT) code in PacFIN is is very similar to bottom trawl catch (everything else in the TWL gear group). <!-- Note that the sample sizes for ages in 2022-2024 are lower than other years, especially midwater in 2022 which only has 14 ages. -->

```{r pacfin-midwater-vs-bottom-figs}
# create separate geargroup2 column which separates midwater from bottom trawl
# see note at 
# https://github.com/pfmc-assessments/PacFIN.Utilities/issues/69#issuecomment-2499162809
bds_clean <- bds_clean |>
  dplyr::mutate(geargroup2 = ifelse(GRID == "MDT", yes = "MDT", no = geargroup))

# length distributions for bottom trawl vs midwater trawl in recent years
bds_clean |>
  filter(geargroup == "TWL", SAMPLE_YEAR >= 2011) |> # exclude all non-trawl gear and pre-catch-shares years
  ggplot(aes(
    x = lengthcm,
    y = forcats::fct_rev(as.factor(SAMPLE_YEAR)),
    color = as.factor(geargroup2)
    #fill = as.factor(geargroup2)
  )) +
  ggridges::geom_density_ridges(alpha = 0.2) +
  labs(
    x = "Length (cm)",
    y = "Year",
  ) + 
  scale_color_discrete(
    name = "Gear",
    breaks = c("MDT", "TWL"),
    labels = c("Midwater trawl", "Bottom trawl")
  )

# age comps from midwater vs bottom trawl
bds_clean |>
  filter(geargroup == "TWL", !is.na(Age),SAMPLE_YEAR >= 2011) |>
  ggplot(aes(
    x = Age,
    y = forcats::fct_rev(as.factor(SAMPLE_YEAR)),
    color = as.factor(geargroup2)
  )) +
  ggridges::geom_density_ridges(
    alpha = 0.2,
    stat = "binline",
    binwidth = 1
  ) +
  labs(
    x = "Age",
    y = "Year",
  ) +
  scale_color_discrete(
    name = "Gear",
    breaks = c("MDT", "TWL"),
    labels = c("Midwater trawl", "Bottom trawl")
  )

```

### Recreational

VERY tentative length sample sizes. I anticipate this is biased high as I have done no filtering.

```{r recfin-bio}
# recent length data
rec_bio <- read.csv(here("Data/Confidential/rec/RecFIN_Lengths.csv")) |>
  tibble::as_tibble() |>
  filter(STATE_NAME == "OREGON" | STATE_NAME == "WASHINGTON" | grepl("REDWOOD", RECFIN_PORT_NAME))

# or mrfss data
or_mrfss <- read.csv(here("Data/Confidential/rec/MRFSS_BIO_2025 CYCLE_433.csv")) |>
  tibble::as_tibble()

or_mrfss_smry <- or_mrfss |> 
  filter(Length_Flag == 'measured') |>
  group_by(Year) |> 
  summarise(n_length = n()) |>
  mutate(STATE_NAME = 'OR (MRFSS)') |>
  tidyr::pivot_wider(names_from = STATE_NAME, values_from = n_length)

# ca/wa mrfss data
ca_wa_mrfss <- read.csv(here("Data/Confidential/rec/MRFSS_lengths_CA_WA.csv")) |>
  as_tibble() |> 
  filter(ST_NAME == 'Washington' | (ST_NAME == 'California' & (CNTY == 15 | CNTY == 23))) |> # 15 = Del Norte, 23 = Humboldt, FIPS codes
  filter(T_LEN %% 1 == 0 | LNGTH %% 1 == 0) # I believe this will filter to measured lengths

ca_wa_mrfss_smry <- ca_wa_mrfss |>
  group_by(YEAR, ST_NAME) |>
  summarise(n_length = n()) |>
  ungroup() |>
  mutate(state = case_when(ST_NAME == 'California' ~ 'CA (MRFSS)',
                           ST_NAME == 'Washington' ~ 'WA (MRFSS)')) |>
  tidyr::pivot_wider(names_from = state, values_from = n_length, id_cols = YEAR, values_fill = 0) |>
  rename(Year = YEAR)

rec_bio |>
  ggplot() +
  geom_density(aes(x = RECFIN_LENGTH_MM, col = STATE_NAME, fill = IS_RETAINED), 
               linewidth = 1, alpha = 0.2) +
  scale_fill_manual(values = c('red', 'blue')) +
  labs('RecFIN length compositions by state and disposition') +
  viridis::scale_color_viridis(discrete = TRUE) 

# Note: 1993 uses total length. 1994 onward uses fork length.
rec_bio |>
  filter(!is.na(RECFIN_LENGTH_MM)) |> 
  mutate(state = case_when(STATE_NAME == 'WASHINGTON' ~'WA',
                           STATE_NAME == 'OREGON' ~ 'OR',
                           STATE_NAME == 'CALIFORNIA' ~ 'CA')) |>
  group_by(RECFIN_YEAR, state, IS_RETAINED) |>
  summarize(n_length = n()) |>
  rename(Year = RECFIN_YEAR) |> 
  tidyr::pivot_wider(names_from = c(state, IS_RETAINED), values_from = n_length, 
                     values_fill = 0) |> 
  full_join(or_mrfss_smry) |>
  full_join(ca_wa_mrfss_smry) |>
  arrange(Year) |> 
  mutate(across(everything(), ~tidyr::replace_na(.x, 0))) |>
  knitr::kable(align = 'l')
```

Retained fish tend to be larger than released fish. However, there are very few released fish. Washington has no measured released fish in RecFIN. Between Oregon and California, `r filter(rec_bio, STATE_NAME != 'WASHINGTON') %>% {100 * with(., sum(IS_RETAINED == 'RETAINED'))/nrow(.)} |> round(1)`% of lengths are for retained fish. Some fraction of those released fish is assumed to have survived, which would skew the ratio even more towards retained fish.

We plan to exclude released fish from composition data.

The fish in Washington also look slightly larger than those in Oregon and California. This difference is more pronounced than it is in survey data, indicating a possible selectivity effect.

### At-Sea

```{r ashop-bio}
ashop_lengths_old <- readxl::read_excel(
  here("Data/Confidential/ASHOP/Oken_YLT_Length data_1976-2023_102824_ASHOP.xlsx"), 
  sheet = "YLT_Length data 1976-1989")
ashop_lengths_new <- suppressWarnings(
  readxl::read_excel(here("Data/Confidential/ASHOP/Oken_YLT_Length data_1976-2023_102824_ASHOP.xlsx"), 
                     sheet = "YLT_Length data1990-2023") # warning is about converting text to numeric
)
ashop_lengths_2024 <- readxl::read_excel(here("Data/Confidential/ASHOP/Oken_YLT_Length data_2024_020425.xlsx")) |>
  mutate(HAUL_JOIN = as.numeric(HAUL_JOIN),
         PERMIT = as.character(PERMIT))

bind_rows(ashop_lengths_old, ashop_lengths_new, ashop_lengths_2024) |>
  group_by(YEAR) |>
  summarise(n_length = sum(FREQUENCY)) |>
  knitr::kable(align = 'l')
```

Figure of length frequencies in at-sea hake fishery for prioritizing which years to age.

```{r ashop-bio-fig}
ashop_lengths_new |> 
  tidyr::uncount(FREQUENCY) |>
  left_join(ashop_catch, by = 'YEAR') |> 
  mutate(catch_mt = EXPANDED_SumOfEXTRAPOLATED_2SECTOR_NUMBER / 1000) |>
  ggplot() +
  ggridges::geom_density_ridges(aes(x = LENGTH, y = YEAR, group = YEAR, 
                                    fill = catch_mt), alpha = 0.5) +
  xlim(30, 65) +
  viridis::scale_fill_viridis()
```

## Survey data

STAT is working on it!

```{r survey, eval=FALSE}
yt_survey_bio <- nwfscSurvey::pull_bio(common_name = 'yellowtail rockfish', survey = 'NWFSC.Combo') 

yt_n_survey_bio <- filter(yt_survey_bio, Latitude_dd > 40 + 1/6)

yt_tri_bio <- yt_survey_bio <- nwfscSurvey::pull_bio(common_name = 'yellowtail rockfish', survey = 'Triennial') 

yt_n_tri_bio <- purrr::map(yt_tri_bio, \(dat) filter(dat, Latitude_dd > 40 + 1/6))


# looking at how growth varies over space and time
# clear break point in selectivity between age 5 and 6.
filter(yt_n_survey_bio, Age_years <= 20, Age_years >= 6) |>
ggplot() +
  geom_point(aes(x = Year, y = Length_cm, col = Age_years), alpha = 0.2) +
  stat_smooth(aes(x = Year, y = Length_cm, group = Age_years, col = Age_years), se = FALSE)
# possible decrease in length at age of older fish in last 4 years of data. TBD with 8 more years!

filter(yt_survey_bio, Age_years <= 20, Age_years >= 6) |>
ggplot() +
  geom_point(aes(x = Latitude_dd, y = Length_cm, col = Age_years), alpha = 0.2) +
  stat_smooth(aes(x = Latitude_dd, y = Length_cm, group = Age_years, col = Age_years), se = FALSE, method = 'lm')
# Larger max size farther north (consistent with theory)

yt_survey_bio |>
  ggplot(aes(x = Latitude_dd, y = Age_years)) +
  geom_point(alpha = 0.1) +
  stat_smooth(se = FALSE)
# Latitudinal age structure: below 43 degrees, avg age ~10, above 45 degrees, avg age ~15

ggplot(yt_n_survey_bio) +
  geom_point(aes(x = Age_years, y = Length_cm, col = Sex), alpha = 0.1)
# Large fish female, old fish male prevails, but not as notable as with canary.

yt_n_survey_bio |>
  group_by(Age_years) |>
  summarise(pct_f = sum(Sex == 'F')/n(),
            se = sqrt(pct_f * (1-pct_f) / n())) |>
  ggplot() +
  geom_point(aes(x = Age_years, y = pct_f)) +
  geom_errorbar(aes(x = Age_years, ymin = pct_f - se, ymax = pct_f + se))

laa_by_lat_lm <- lm(Length_cm ~ I(Latitude_dd-mean(Latitude_dd))*factor(Age_years), 
                                   data = yt_n_survey_bio, 
                      subset = Age_years < 20 & Age_years >= 6)

laa_by_age <- lm(Length_cm ~ factor(Age_years), data = yt_n_survey_bio, 
                      subset = Age_years < 20 & Age_years >= 6)

W_L_pars <- yt_n_survey_bio |>
  dplyr::mutate(Sex = 'all') |> # this will make it so a single curve is fit to all sexes, in addition to sex-specific curves
  dplyr::bind_rows(yt_n_survey_bio) |>
  dplyr::filter(Sex %in% c('F', 'M', 'all')) |>
  tidyr::nest(data = -Sex) |> 
                                         # Fit model
  dplyr::mutate(fit = purrr::map(data, ~ lm(log(Weight_kg / 1000) ~ log(Length_cm), data = .)),
                tidied = purrr::map(fit, broom::tidy),
                # Transform W-L parameters, account for lognormal bias
                out = purrr::map2(tidied, fit, function(.x, .y) {
                  sd_res <- sigma(.y)
                  .x |>
                    dplyr::mutate(term = c('A', 'B'),
                                  median = ifelse(term == 'A', exp(estimate), estimate),
                                  mean = ifelse(term == 'A', median * exp(0.5 * sd_res^2),
                                                median)) |>
                    dplyr::select(term, mean)
                }),
                n = purrr::map(fit, ~ length(resid(.)))) |>
  tidyr::unnest(c(out, n)) |>
  dplyr::select(sex = Sex, term, mean, n) |>
  tidyr::pivot_wider(names_from = term, values_from = mean) |>
  dplyr::mutate(sex = dplyr::case_when(sex == 'F' ~ 'female',
                                       sex == 'M' ~ 'male',
                                       TRUE ~ sex))

write.csv(W_L_pars, here('Data/Processed/W_L_pars.csv'), row.names = FALSE)

### Megan this is where I look at time-varying weight-length
W_L_pars |>
  dplyr::mutate(out.dfr = purrr::map2(A, B, ~ dplyr::tibble(len = 1:max(yt_n_survey_bio$Length_cm, na.rm = TRUE), 
                                                            wgt = 1000 * .x*len^.y))) |>
  tidyr::unnest(out.dfr) |>
  dplyr::filter(Sex != 'B') |>
  ggplot() +
  geom_point(aes(x = Length_cm, y = Weight, col = Sex), alpha = 0.15, 
             data = dplyr::filter(yt_n_survey_bio, Sex != 'U')) +
  geom_line(aes(x = len, y = wgt, col = Sex), linewidth = 1) +
  labs(x = 'Length (cm)', y = 'Weight (kg)') +
  scale_color_manual(values = c('F' = 'red', 'M' = 'blue')) +
  facet_wrap(~ Year) 

yt_n_survey_bio |>
  dplyr::filter(!is.na(Length_cm), !is.na(Weight_kg)) %>%
  broom::augment(lm(log(Weight_kg) ~ log(Length_cm), data = .),
                 .) |>
  group_by(Year) |>
  summarise(mean_resid = mean(.resid)) |>
  ggplot() +
  geom_line(aes(x = Year, y = mean_resid)) +
  geom_hline(yintercept = 0)

```
